{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path = ''#'../Projects/walker/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"BipedalWalkerHardcore-v3v1log.txt\",'r')\n",
    "#print(f.readline())\n",
    "#f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"BipedalWalkerHardcore-v3v2log.txt\",'r')\n",
    "\n",
    "rewards = []\n",
    "for line in f.readlines():\n",
    "    reward = float(line.split(',')[1].split(\"\\n\")[0])\n",
    "    #break\n",
    "    rewards.append(reward)\n",
    "f.close()\n",
    "\n",
    "def movingaverage(interval, window_size):\n",
    "    window= np.ones(int(window_size))/float(window_size)\n",
    "    return np.convolve(interval, window, 'same')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13742e690>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.plot(rewards,'.')\n",
    "plt.plot(movingaverage(rewards,100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in policy for testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Implementation of TD3 Algorithm on Open AI gym environment BipedalWalkerHardcore v3\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, max_size=5e5):\n",
    "        self.buffer = []\n",
    "        self.max_size = int(max_size)\n",
    "        self.size = 0\n",
    "    \n",
    "    def add(self, transition):\n",
    "        self.size +=1\n",
    "        # transiton is tuple of (state, action, reward, next_state, done)\n",
    "        self.buffer.append(transition)\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        # delete 1/5th of the buffer when full\n",
    "        if self.size > self.max_size:\n",
    "            del self.buffer[0:int(self.size/5)]\n",
    "            self.size = len(self.buffer)\n",
    "        \n",
    "        indexes = np.random.randint(0, len(self.buffer), size=batch_size)\n",
    "        state, action, reward, next_state, done = [], [], [], [], []\n",
    "        \n",
    "        for i in indexes:\n",
    "            s, a, r, s_, d = self.buffer[i]\n",
    "            state.append(np.array(s, copy=False))\n",
    "            action.append(np.array(a, copy=False))\n",
    "            reward.append(np.array(r, copy=False))\n",
    "            next_state.append(np.array(s_, copy=False))\n",
    "            done.append(np.array(d, copy=False))\n",
    "        \n",
    "        return np.array(state), np.array(action), np.array(reward), np.array(next_state), np.array(done)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, max_action):\n",
    "        super(Actor, self).__init__()\n",
    "        \n",
    "        self.l1 = nn.Linear(state_dim, 400)\n",
    "        self.l2 = nn.Linear(400, 300)\n",
    "        self.l3 = nn.Linear(300, action_dim)\n",
    "        \n",
    "        self.max_action = max_action\n",
    "        \n",
    "    def forward(self, state):\n",
    "        \"\"\"\n",
    "        Pass the state through mlp, and emit a value between -1 and 1, scaled by max action size. \n",
    "        \n",
    "        Returns the action to take (along each dim of action dim)\n",
    "        \"\"\"\n",
    "        a = F.relu(self.l1(state))\n",
    "        a = F.relu(self.l2(a))\n",
    "        a = torch.tanh(self.l3(a)) * self.max_action\n",
    "        return a\n",
    "        \n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super(Critic, self).__init__()\n",
    "        \n",
    "        self.l1 = nn.Linear(state_dim + action_dim, 400)\n",
    "        self.l2 = nn.Linear(400, 300)\n",
    "        self.l3 = nn.Linear(300, 1)\n",
    "        \n",
    "    def forward(self, state, action):\n",
    "        \"\"\"\n",
    "        Returns a Q(!) value for the network, given a state action input. The input is concatted and passed through an MLP\n",
    "        of roughly the same size as before, but different input dim to account for the action(s) taken. \n",
    "        \"\"\"\n",
    "        state_action = torch.cat([state, action], 1)\n",
    "        \n",
    "        q = F.relu(self.l1(state_action))\n",
    "        q = F.relu(self.l2(q))\n",
    "        q = self.l3(q)\n",
    "        return q\n",
    "    \n",
    "class TD3:\n",
    "    def __init__(self, lr, state_dim, action_dim, max_action):\n",
    "        \n",
    "        self.actor = Actor(state_dim, action_dim, max_action).to(device)\n",
    "        self.actor_target = Actor(state_dim, action_dim, max_action).to(device)\n",
    "        self.actor_target.load_state_dict(self.actor.state_dict())\n",
    "        self.actor_optimizer = optim.Adam(self.actor.parameters(), lr=lr)\n",
    "        \n",
    "        self.critic_1 = Critic(state_dim, action_dim).to(device)\n",
    "        self.critic_1_target = Critic(state_dim, action_dim).to(device)\n",
    "        self.critic_1_target.load_state_dict(self.critic_1.state_dict())\n",
    "        self.critic_1_optimizer = optim.Adam(self.critic_1.parameters(), lr=lr)\n",
    "        \n",
    "        self.critic_2 = Critic(state_dim, action_dim).to(device)\n",
    "        self.critic_2_target = Critic(state_dim, action_dim).to(device)\n",
    "        self.critic_2_target.load_state_dict(self.critic_2.state_dict())\n",
    "        self.critic_2_optimizer = optim.Adam(self.critic_2.parameters(), lr=lr)\n",
    "        \n",
    "        self.max_action = max_action\n",
    "    \n",
    "    def select_action(self, state):\n",
    "        \"\"\"\n",
    "        Pass the state (after casted to right type) through the actor network \n",
    "        \"\"\"\n",
    "        state = torch.FloatTensor(state.reshape(1, -1)).to(device)\n",
    "        return self.actor(state).cpu().data.numpy().flatten()\n",
    "    \n",
    "    def update(self, replay_buffer, n_iter, batch_size, gamma, polyak, policy_noise, noise_clip, policy_delay):\n",
    "        \"\"\"\n",
    "        Update the actor and critic networks. The difference here between TD3 and DDPG is that there\n",
    "        \n",
    "        are now two critic newtworks, both of which compute the Q value, and we designate our\n",
    "        target Q value as the smaller between the two critic network predictions. \n",
    "        \"\"\"\n",
    "        for i in range(n_iter):\n",
    "            # Sample a batch of transitions from replay buffer:\n",
    "            \n",
    "            # providing us with our s a r s' done tuple. \n",
    "            state, action_, reward, next_state, done = replay_buffer.sample(batch_size)\n",
    "            state = torch.FloatTensor(state).to(device)\n",
    "            action = torch.FloatTensor(action_).to(device)\n",
    "            reward = torch.FloatTensor(reward).reshape((batch_size,1)).to(device)\n",
    "            next_state = torch.FloatTensor(next_state).to(device)\n",
    "            done = torch.FloatTensor(done).reshape((batch_size,1)).to(device)\n",
    "            \n",
    "            # Select next action according to target policy:\n",
    "            \n",
    "            # the next action we take is chosen by pasing our next state vector into the target policy network\n",
    "            # the target policy network, a polyak averaged slowly updating version of the current policy network. \n",
    "            \n",
    "            noise = torch.FloatTensor(action_).data.normal_(0, policy_noise).to(device) # we still use noise for our target? \n",
    "            noise = noise.clamp(-noise_clip, noise_clip) # this val pre-defined as at most .5\n",
    "            next_action = (self.actor_target(next_state) + noise) # actor predicts next action choice, and we sprinkle in a little noise\n",
    "            next_action = next_action.clamp(-self.max_action, self.max_action) #clipped. \n",
    "            \n",
    "            # Compute target Q-value:\n",
    "            # Using our next state from replay buffer and what the actor network chose as next action, can \n",
    "            # compute Q value for this action for both state critic nets.\n",
    "            target_Q1 = self.critic_1_target(next_state, next_action) # Note these are the critic target networks, i.e a older version of critic network to avoid model chasing it's own tail. \n",
    "            target_Q2 = self.critic_2_target(next_state, next_action)\n",
    "            target_Q = torch.min(target_Q1, target_Q2) # take the min, to avoid over-estimation bias\n",
    "            target_Q = reward + ((1-done) * gamma * target_Q).detach() # convert to proper form, i.e TD bellman etc. update rule\n",
    "            \n",
    "            # Optimize Critic 1:\n",
    "            current_Q1 = self.critic_1(state, action) # this is supposed to be the same Q value, but one timestep earlier\n",
    "            loss_Q1 = F.mse_loss(current_Q1, target_Q) # MSE loss, \n",
    "            self.critic_1_optimizer.zero_grad()\n",
    "            loss_Q1.backward()\n",
    "            self.critic_1_optimizer.step()\n",
    "            \n",
    "            # Optimize Critic 2:\n",
    "            current_Q2 = self.critic_2(state, action)\n",
    "            loss_Q2 = F.mse_loss(current_Q2, target_Q)\n",
    "            self.critic_2_optimizer.zero_grad()\n",
    "            loss_Q2.backward() #and backward + step for both\n",
    "            self.critic_2_optimizer.step()\n",
    "            \n",
    "            # Delayed policy updates: \n",
    "            \n",
    "            # we also want to improve our policy net, but this is done less frequently than critic updates\n",
    "            if i % policy_delay == 0:\n",
    "                # Compute actor loss:\n",
    "                actor_loss = -self.critic_1(state, self.actor(state)).mean() #actor loss is defined as \n",
    "                # - Q value of all batches, passed backward through actor.\n",
    "                \n",
    "                # why only the first critic? What if it the worse estimator of Q values than critic 1? \n",
    "                \n",
    "                # Optimize the actor\n",
    "                self.actor_optimizer.zero_grad()\n",
    "                actor_loss.backward()\n",
    "                self.actor_optimizer.step()\n",
    "                \n",
    "                # Polyak averaging update:\n",
    "                for param, target_param in zip(self.actor.parameters(), self.actor_target.parameters()):\n",
    "                    target_param.data.copy_( (polyak * target_param.data) + ((1-polyak) * param.data))\n",
    "                \n",
    "                for param, target_param in zip(self.critic_1.parameters(), self.critic_1_target.parameters()):\n",
    "                    target_param.data.copy_( (polyak * target_param.data) + ((1-polyak) * param.data))\n",
    "                \n",
    "                for param, target_param in zip(self.critic_2.parameters(), self.critic_2_target.parameters()):\n",
    "                    target_param.data.copy_( (polyak * target_param.data) + ((1-polyak) * param.data))\n",
    "                    \n",
    "                \n",
    "    def save(self, directory, name):\n",
    "        torch.save(self.actor.state_dict(), '%s/%s_actor.pth' % (directory, name))\n",
    "        torch.save(self.actor_target.state_dict(), '%s/%s_actor_target.pth' % (directory, name))\n",
    "        \n",
    "        torch.save(self.critic_1.state_dict(), '%s/%s_crtic_1.pth' % (directory, name))\n",
    "        torch.save(self.critic_1_target.state_dict(), '%s/%s_critic_1_target.pth' % (directory, name))\n",
    "        \n",
    "        torch.save(self.critic_2.state_dict(), '%s/%s_crtic_2.pth' % (directory, name))\n",
    "        torch.save(self.critic_2_target.state_dict(), '%s/%s_critic_2_target.pth' % (directory, name))\n",
    "        \n",
    "    def load(self, directory, name):\n",
    "        self.actor.load_state_dict(torch.load('%s/%s_actor.pth' % (directory, name), map_location=lambda storage, loc: storage))\n",
    "        self.actor_target.load_state_dict(torch.load('%s/%s_actor_target.pth' % (directory, name), map_location=lambda storage, loc: storage))\n",
    "        \n",
    "        self.critic_1.load_state_dict(torch.load('%s/%s_crtic_1.pth' % (directory, name), map_location=lambda storage, loc: storage))\n",
    "        self.critic_1_target.load_state_dict(torch.load('%s/%s_critic_1_target.pth' % (directory, name), map_location=lambda storage, loc: storage))\n",
    "        \n",
    "        self.critic_2.load_state_dict(torch.load('%s/%s_crtic_2.pth' % (directory, name), map_location=lambda storage, loc: storage))\n",
    "        self.critic_2_target.load_state_dict(torch.load('%s/%s_critic_2_target.pth' % (directory, name), map_location=lambda storage, loc: storage))\n",
    "        \n",
    "        \n",
    "    def load_actor(self, directory, name):\n",
    "        self.actor.load_state_dict(torch.load('%s/%s_actor.pth' % (directory, name), map_location=lambda storage, loc: storage))\n",
    "        self.actor_target.load_state_dict(torch.load('%s/%s_actor_target.pth' % (directory, name), map_location=lambda storage, loc: storage))\n",
    "        \n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Hyperparameters #########\n",
    "env_name = \"BipedalWalkerHardcore-v3\"\n",
    "\n",
    "log_interval = 100           # print avg reward after interval\n",
    "random_seed = 0\n",
    "gamma = 0.99                # discount for future rewards\n",
    "batch_size = 500          # num of transitions sampled from replay buffer\n",
    "lr = 0.0001\n",
    "exploration_noise = 0.1 \n",
    "polyak = 0.995              # target policy update parameter (1-tau)\n",
    "policy_noise = 0.2          # target policy smoothing noise\n",
    "noise_clip = 0.5\n",
    "policy_delay = 2            # delayed policy updates parameter\n",
    "max_episodes = 30000         # max num of episodes\n",
    "max_timesteps = 5000        # max timesteps in one episode\n",
    "directory = path + \"preTrained/\" # save trained models\n",
    "filename = \"TD3_{}_{}\".format(env_name, random_seed)\n",
    "#RENDER_INTERVAL = 50\n",
    "###################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1\tReward: 269\n",
      "Episode: 2\tReward: -74\n",
      "Episode: 3\tReward: -44\n",
      "Episode: 4\tReward: 34\n",
      "Episode: 5\tReward: -81\n",
      "Episode: 6\tReward: 18\n",
      "Episode: 7\tReward: 114\n",
      "Episode: 8\tReward: 45\n",
      "Episode: 9\tReward: -104\n",
      "Episode: 10\tReward: 29\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "env_name = \"BipedalWalkerHardcore-v3\"\n",
    "#agent_name = \"BipedalWalker-v3\"\n",
    "random_seed = 0\n",
    "n_episodes = 10\n",
    "lr = 0.002 # not used \n",
    "max_timesteps = 6000\n",
    "render = True\n",
    "save_gif = False\n",
    "\n",
    "filename = \"TD3_{}_{}\".format(env_name, random_seed)\n",
    "#filename += '_solved'\n",
    "#directory = \"preTrained/{}\".format(env_name)\n",
    "\n",
    "env = gym.make(env_name)\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.shape[0]\n",
    "max_action = float(env.action_space.high[0])\n",
    "\n",
    "policy = TD3(lr, state_dim, action_dim, max_action)\n",
    "\n",
    "policy.load_actor(directory, filename)\n",
    "\n",
    "for ep in range(1, n_episodes+1):\n",
    "    ep_reward = 0\n",
    "    state = env.reset()\n",
    "    for t in range(max_timesteps):\n",
    "        action = policy.select_action(state)\n",
    "       # print(action)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        ep_reward += reward\n",
    "        if render:\n",
    "            env.render()\n",
    "            if save_gif:\n",
    "                img = env.render(mode = 'rgb_array')\n",
    "                img = Image.fromarray(img)\n",
    "                img.save('./gif/{}.jpg'.format(t))\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    print('Episode: {}\\tReward: {}'.format(ep, int(ep_reward)))\n",
    "    ep_reward = 0\n",
    "    env.close()        \n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
